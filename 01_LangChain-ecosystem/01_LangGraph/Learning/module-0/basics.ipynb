{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjv7GZWNGat1kRYtMAFxKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashhadxali/AgenticAI/blob/main/01_LangChain-ecosystem/01_LangGraph/Learning/module-0/basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%pip` and `!pip` are both used in Jupyter Notebook environments for installing Python packages, but they differ in their behavior and the context in which they operate:\n",
        "\n",
        "### Key Difference:\n",
        "- `%pip` directly interacts with the kernel and ensures proper integration with the Jupyter Notebook environment.\n",
        "- `!pip` runs as an external command and might target a different Python environment than the one used in the notebook.\n",
        "\n",
        "### Recommendation:\n",
        "- Use `%pip` in Jupyter Notebooks to avoid issues related to mismatched environments.\n",
        "\n",
        "---\n",
        "### Code Explanation:\n",
        "Yeh code **AI tools ko asaan aur powerful banane** ke liye zaruri packages install karta hai, jo **chatbots** aur **automation systems** banane me madad karte hain.\n",
        "\n",
        "1. **`%%capture --no-stderr`**:\n",
        "   - Installation ke output aur errors ko hide karne ke liye, taki notebook organized lage.  \n",
        "\n",
        "2. **`!pip install`**:\n",
        "   - External Python libraries install karne ke liye.  \n",
        "   - **`-q`**: Quiet mode me install karta hai, minimal output ke saath.\n",
        "\n",
        "---\n",
        "\n",
        "### Installed Packages:\n",
        "1. **LangChain OpenAI**: GPT-4 aur other OpenAI models ke liye.  \n",
        "2. **LangChain Core**: AI workflows aur logic chains banane ke liye.  \n",
        "3. **LangChain Community**: Extra tools aur features ke liye.  \n",
        "4. **Tavily Python**: Specific AI tool ya automation ke liye.  \n",
        "5. **LangChain Google GenAI**: Google ke AI models (e.g., Gemini) ke saath kaam karne ke liye.\n",
        "\n",
        "---\n",
        "\n",
        "### **Purpose**:\n",
        "- Yeh tools AI-based projects aur applications ko banane me madad karte hain.  \n",
        "- **Why these libraries?** LangChain ka ecosystem AI models ko zyada efficient aur structured tarike se integrate karne ke liye bana hai.  \n",
        "- **Without these?** AI workflows aur integrations complex ya limited ho sakte hain.\n",
        "\n",
        "Agar tum AI-based projects par kaam kar rahe ho, yeh tools bohot kaam aayenge. 😊"
      ],
      "metadata": {
        "id": "jWO4UzpCgW60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "#%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python\n",
        "\n",
        "!pip install -q langchain_google_genai langchain_core langchain_community tavily-python"
      ],
      "metadata": {
        "id": "AshzIdwwce6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeh code Google ke Gemini AI model ko LangChain ke sath integrate kar raha hai. Har step ko detail me samajhte hain:\n",
        "\n",
        "### 1. **`from langchain_google_genai import ChatGoogleGenerativeAI`**\n",
        "   - Is line se Google Generative AI (Gemini) ke liye LangChain ka chat model import kiya ja raha hai.  \n",
        "   - **Purpose:** Gemini model ke sath baat karne ke liye ek interface provide karta hai.\n",
        "\n",
        "### 2. **`from google.colab import userdata`**\n",
        "   - Colab ke `userdata` module se sensitive data (jaise API keys) ko access karne ke liye use hota hai.  \n",
        "   - **Purpose:** GEMINI API key ko secure tareeke se fetch karna.\n",
        "\n",
        "### 3. **`GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')`**\n",
        "   - GEMINI API key ko `userdata` se access karke variable me store kar raha hai.  \n",
        "   - **Purpose:** API key ke bina Google Gemini model ko access nahi kar sakte.\n",
        "\n",
        "### 4. **`llm = ChatGoogleGenerativeAI(...)`**\n",
        "   - Ek instance banaya gaya hai jo Google ke Gemini AI model ko represent karta hai. Iske parameters samajhte hain:  \n",
        "     \n",
        "     - **`model = \"gemini-1.5-flash\"`:**  \n",
        "       Gemini AI ka specific version select kar raha hai, yeh ek fast aur latest model hai.  \n",
        "     \n",
        "     - **`api_key = GEMINI_API_KEY`:**  \n",
        "       Gemini API access karne ke liye key provide karta hai.  \n",
        "     \n",
        "     - **`temperature = 0`:**  \n",
        "       - Temperature AI model ke output randomness ko control karta hai.  \n",
        "       - Value **0 se 1** ke beech hoti hai:  \n",
        "         - **0:** Bilkul predictable aur straight-forward output deta hai.  \n",
        "         - **1:** Zyada creative aur random responses deta hai.  \n",
        "       - Yahan **0** use kiya gaya hai, iska matlab output bilkul precise hoga.\n",
        "\n",
        "### **Summary:**\n",
        "- Yeh code **Google Gemini AI model** ko use karne ke liye setup kar raha hai.\n",
        "- **Key Features:**  \n",
        "  1. Gemini ke latest model **(gemini-1.5-flash)** ka use.  \n",
        "  2. Predictable output (temperature = 0).  \n",
        "  3. Secure API key handling.  \n",
        "\n",
        "Agar tum AI-based applications banana chahte ho jo Google ke Gemini model ko use karein, to yeh code base kaam karega. 😊"
      ],
      "metadata": {
        "id": "ssypRrbkjzdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "\n",
        "    api_key=GEMINI_API_KEY,\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "_rMZUn79dEGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeh code ek **joke** generate karta hai:\n",
        "\n",
        "1. **`llm.invoke(\"Tell me a joke\")`**: Gemini AI se joke maangta hai.  \n",
        "2. **`result`**: Joke ka response yahan save hota hai.  \n",
        "3. **Output**: Joke print hoga, jaise:  \n",
        "   > Why did the scarecrow win an award?  \n",
        "   > Because he was outstanding in his field!  \n",
        "\n",
        "Bas! Tumhare AI se joke lena itna simple hai. 😊"
      ],
      "metadata": {
        "id": "AxG9PfIol63Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm.invoke(\"who won 2024 election?\") #Human message\n",
        "result #AIMessage\n",
        "\n",
        "#It is not updated yet and is not capable to search the latest news."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBzIUdS9lnzE",
        "outputId": "631b07a8-aa4c-4291-c352-b9e7f35beedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The 2024 U.S. Presidential election has not yet occurred.  It will be held on November 5, 2024.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-5066f830-e90d-4496-b7dd-0a8b3f48d471-0', usage_metadata={'input_tokens': 10, 'output_tokens': 34, 'total_tokens': 44, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeh code AI model ko ek message list bhej kar response lene ke liye likha gaya hai. Aasan aur short explanation:\n",
        "\n",
        "1. **`HumanMessage`**: Ek human message create karta hai.  \n",
        "   - **`content=\"Hi\"`**: Message ka text.  \n",
        "   - **`name=\"Ashhad\"`**: Message bhejne wale ka naam.  \n",
        "\n",
        "2. **`messages = [msg]`**: Messages ko ek list me rakha.  \n",
        "\n",
        "3. **`llm.invoke(messages)`**:  \n",
        "   - AI model ko messages bhejta hai.  \n",
        "   - Model uska response generate karega.\n",
        "\n",
        "### Output:\n",
        "Model ka response tumhare input **(\"Hi\")** ke hisaab se aayega, jaise:  \n",
        "> Hello, Ashhad! How can I assist you? 😊\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------\n",
        "Yeh code **LangChain** ka message-based communication feature use kar raha hai, jo multi-turn conversations ke liye helpful hota hai.  \n",
        "\n",
        "### **Purpose**:\n",
        "1. **Why used:**  \n",
        "   - Ek **structured way** me AI model ko multiple messages bhejne aur response lene ke liye.  \n",
        "   - Yeh conversational AI systems (e.g., chatbots) banane me kaam aata hai.  \n",
        "\n",
        "2. **Why this code, not something else?**  \n",
        "   - **Direct string use karne ki jagah:**  \n",
        "     - **`HumanMessage`** sender ka naam aur content ka structure maintain karta hai, jo zyada readable aur organized hai.  \n",
        "   - **Message list:** Agar multiple messages bhejne ho (conversation context), to list ka format zaruri hai.  \n",
        "\n",
        "Agar tumhara kaam conversational AI se related hai, to yeh approach best hai. Single-message ke liye direct string bhi chal sakti hai, lekin context track nahi hoga. 😊"
      ],
      "metadata": {
        "id": "rPC_eTW6gdF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# # Create a message\n",
        "# msg = HumanMessage(content=\"Hi\", name=\"Ashhad\") #content and sender name\n",
        "\n",
        "# # Message list\n",
        "# messages = [msg] #list\n",
        "\n",
        "# #invoke the model with a list of messages\n",
        "# llm.invoke(messages)"
      ],
      "metadata": {
        "id": "r07MwsmErn8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeh code ek **multi-turn conversation** AI system ke liye hai jo LangChain framework ka use karta hai. Har step ka explanation aur **purpose** samajhte hain:\n",
        "\n",
        "### Code Explanation:\n",
        "1. **`HumanMessage`**:\n",
        "   - **Content:** User ka message, e.g., \"Hi\" aur \"How can I learn?\"  \n",
        "   - **Name:** Message bhejne wale ka naam, yahan **Ashhad**.  \n",
        "\n",
        "2. **`AIMessage`**:\n",
        "   - **Content:** AI ka response, e.g., \"LangChain is a framework for developing applications powered by large language models (LLMs).\"  \n",
        "   - **Name:** AI assistant ka naam, e.g., **AIAssistant**.\n",
        "\n",
        "3. **`messages` List**:\n",
        "   - Messages ko ek list me store kiya gaya hai jo conversation ka flow dikhata hai.  \n",
        "   - AI ko context samajhne ke liye yeh zaruri hai.\n",
        "\n",
        "4. **`llm.invoke(messages)`**:\n",
        "   - AI model ko messages ka list diya ja raha hai.  \n",
        "   - Model pura context padhega aur latest input ka relevant response generate karega.\n",
        "\n",
        "---\n",
        "\n",
        "### Purpose:\n",
        "1. **Why use this approach?**\n",
        "   - Multi-turn conversations ka **context maintain** karne ke liye.  \n",
        "   - Har message ke sath sender ka naam aur role track hota hai (e.g., Human vs. AI).  \n",
        "\n",
        "2. **Why not simple strings?**\n",
        "   - Strings me naam aur role ka structure nahi hota, is wajah se context samajhna mushkil hota hai.  \n",
        "   - **`HumanMessage`** aur **`AIMessage`** se structure aur clarity aati hai.\n",
        "\n",
        "---\n",
        "\n",
        "### Output:\n",
        "AI last message ka response dega, e.g.:  \n",
        "> You can learn LangChain by reading the documentation, watching tutorials, and building projects. 😊"
      ],
      "metadata": {
        "id": "iyuo3xcRlg9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "messages = [\n",
        "    HumanMessage(content=\"Hi\", name=\"Ashhad\"),\n",
        "    AIMessage(content=\"Hello, Ashhad! How can I assist you?😊 \\n\", name=\"AIAssistant\"),\n",
        "    HumanMessage(content=\"What is Langchain\", name=\"Ashhad\"),\n",
        "    AIMessage(content=\"LangChain is a framework for developing applications powered by large language models (LLMs). \\n\", name=\"AIAssistant\"),\n",
        "    HumanMessage(content=\"How can i learn?\", name=\"Ashhad\")\n",
        "]\n",
        "\n",
        "#invoke the model with a list of messages\n",
        "llm.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46CKLuYNhgpg",
        "outputId": "177e1876-cce0-436d-a3bf-e69de9fa7b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='There are several ways to learn LangChain, depending on your learning style and prior experience:\\n\\n**1. Official Documentation and Tutorials:**\\n\\n* **LangChain\\'s official website:** This is the best starting point.  It contains comprehensive documentation, tutorials, and examples.  Start with the \"Getting Started\" section.  Look for their examples and try to replicate them.  This is crucial for understanding the core concepts.\\n\\n**2. Hands-on Projects:**\\n\\n* **Start small:** Don\\'t try to build a complex application right away. Begin with simple projects, like building a chatbot that answers questions from a specific document or creating a simple question-answering system.  The LangChain documentation provides excellent examples to get you started.\\n* **Iterate and experiment:**  The best way to learn is by doing.  Try different components, modify existing examples, and see what happens.  Don\\'t be afraid to break things – that\\'s how you learn.\\n* **Find a project that interests you:**  This will keep you motivated and engaged in the learning process.  Think about a problem you can solve using LLMs and LangChain.\\n\\n**3. Online Courses and Resources:**\\n\\n* **YouTube tutorials:** Search for \"LangChain tutorial\" on YouTube.  Many creators have produced videos explaining different aspects of LangChain.  Look for tutorials that cover the basics and then move on to more advanced topics.\\n* **Blogs and articles:** Numerous blogs and articles discuss LangChain and its applications.  Searching for specific topics (e.g., \"LangChain memory,\" \"LangChain agents\") will yield relevant results.\\n* **Community forums:** Engage with the LangChain community on platforms like GitHub or Discord.  Asking questions and participating in discussions is a great way to learn from others and get help when you\\'re stuck.\\n\\n**4.  Understanding Prerequisites:**\\n\\nBefore diving into LangChain, it\\'s helpful to have a basic understanding of:\\n\\n* **Python:** LangChain is a Python library, so familiarity with Python programming is essential.\\n* **LLMs:**  Having a conceptual understanding of how LLMs work will help you appreciate LangChain\\'s capabilities.  You don\\'t need to be an expert, but knowing the basics will be beneficial.\\n\\n\\n**Learning Path Suggestion:**\\n\\n1. **Read the official LangChain documentation\\'s \"Getting Started\" section.** This will give you a foundational understanding.\\n2. **Work through a few simple tutorials from the documentation or YouTube.**  Focus on understanding the core concepts like chains, indexes, and agents.\\n3. **Choose a small project that interests you and try to build it using LangChain.**  This is where you\\'ll solidify your understanding.\\n4. **Explore more advanced features and components of LangChain as you gain confidence.**\\n\\n\\nRemember to be patient and persistent. Learning a new framework takes time and effort.  Don\\'t get discouraged if you encounter challenges – that\\'s part of the learning process.  The LangChain community is generally very helpful, so don\\'t hesitate to ask for assistance when needed.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-8e5a098d-5e96-4659-9d7c-7de546262b57-0', usage_metadata={'input_tokens': 48, 'output_tokens': 643, 'total_tokens': 691, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "Yeh code **Tavily Search Tool** ko LangChain ke saath integrate karta hai, jo AI applications me search functionality provide karta hai.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step-by-Step Explanation**:\n",
        "\n",
        "1. **`import os`**:\n",
        "   - **Purpose**: Environment variables set karne ke liye zaruri hai.\n",
        "   - **Use**: API key ko globally accessible banata hai, taki Tavily tool usse use kar sake.\n",
        "\n",
        "2. **`from google.colab import userdata`**:\n",
        "   - **Purpose**: Google Colab se secure tariqe se API key ko retrieve karna.\n",
        "\n",
        "3. **API Key Setup**:\n",
        "   ```python\n",
        "   TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "   os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "   ```\n",
        "   - **Purpose**: Tavily service ke liye zaruri authentication key ko set karna.\n",
        "\n",
        "4. **`from langchain_community.tools.tavily_search import TavilySearchResults`**:\n",
        "   - **Purpose**: Tavily Search Tool ko import karna, jo LangChain ka ek feature hai.\n",
        "\n",
        "5. **Tool Initialization**:\n",
        "   ```python\n",
        "   tool = TavilySearchResults(max_result=2)\n",
        "   tavily_search = TavilySearchResults(max_results=3, api_key=TAVILY_API_KEY)\n",
        "   ```\n",
        "   - **Purpose**: Search tool initialize karte hain.  \n",
        "   - **Parameters**: `max_results` specify karta hai ki search ke maximum kitne results chahiye.\n",
        "\n",
        "6. **Search Query**:\n",
        "   ```python\n",
        "   search_docs = tavily_search.invoke(\"What is Langchain?\")\n",
        "   ```\n",
        "   - **Purpose**: Query run karta hai aur Tavily search tool se results return karta hai.\n",
        "\n",
        "---\n",
        "\n",
        "### **The Mistake**:\n",
        "- Tumne pehle `os` module import nahi kiya tha.  \n",
        "- Jab `os.environ[\"TAVILY_API_KEY\"]` likha, to error aaya kyunki `os` imported nahi tha.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Why this happened?**:\n",
        "- **`os.environ`**: Python ka ek method hai jo `os` module ka part hai. Agar `os` ko import nahi karte, to Python is method ko pehchan nahi sakta.  \n",
        "- **Solution**: Code ke start me `import os` add karne se problem solve ho gayi.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Lesson**:\n",
        "Jab bhi environment variables set karne ho ya unhe access karna ho (`os.environ`), `os` module ko import karna zaruri hai. Without it, code run nahi karega. 😊"
      ],
      "metadata": {
        "id": "KTzJ-mOjciy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_search = TavilySearchResults(max_results=3, api_key=TAVILY_API_KEY)\n",
        "search_docs = tavily_search.invoke(\"Who won the US 2024 election?\")\n",
        "#print(search_docs)\n",
        "\n",
        "\n",
        "#Tavily is up to date and is capable to search the latest news."
      ],
      "metadata": {
        "id": "UOJHNO8_rvdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`search_docs` Tavily Search Tool se query ka result store karta hai.  \n",
        "\n",
        "### Code:\n",
        "```python\n",
        "search_docs = tavily_search.invoke(\"Who won the US 2024 election?\")\n",
        "```\n",
        "\n",
        "### Use:\n",
        "- Query run karta hai aur results ko **`search_docs`** me save karta hai.  \n",
        "- Display karne ke liye:\n",
        "  ```python\n",
        "  print(search_docs)\n",
        "  ```"
      ],
      "metadata": {
        "id": "7E9-yOxjeO6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWs5VSLhc53k",
        "outputId": "d162e401-0d77-4090-e7a6-226f62a62101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.bbc.co.uk/news/election/2024/us/results',\n",
              "  'content': 'US Presidential Election Results 2024 - BBC News Close menu BBC News Kamala Harris of the Democrat party has 27 electoral college votes. Donald Trump of the Republican party has 90 electoral college votes. Kamala Harris of the Democrat party has 10,652,749 votes (44.9%) Donald Trump of the Republican party has 12,812,102 votes (54.0%) US presidential election results 2024 US election 2024 Voting in some states is particularly hard to predict, with polls showing they could be won by the Republicans or the Democratic party. Voters in 11 states will also elect a governor. How to follow the US election on the BBC Path to 270: The states Harris and Trump need to win US election 2024 About the BBC'},\n",
              " {'url': 'https://www.bbc.com/news/election/2024/us/results',\n",
              "  'content': 'US Presidential Election Results 2024 - BBC News Close menu BBC News Kamala Harris of the Democrat party has 0 electoral college votes. Donald Trump of the Republican party has 0 electoral college votes. Kamala Harris of the Democrat party has 158,810 votes (38.4%) Donald Trump of the Republican party has 249,225 votes (60.2%) US presidential election results 2024 US election 2024 Voting in some states is particularly hard to predict, with polls showing they could be won by the Republicans or the Democratic party. The battleground states that could decide the 2024 presidential election are: Voters in 11 states will also elect a governor. US election polls: Who is ahead - Harris or Trump? US election 2024 About the BBC'},\n",
              " {'url': 'https://www.latimes.com/politics/story/2024-11-06/trump-defeats-harris-47th-president-election-2024',\n",
              "  'content': 'Trump wins 2024 U.S. presidential election - Los Angeles Times Trump elected 47th president of the United States, defeating Harris to retake White House Nancy Northup, President and CEO of the Center for Reproductive Rights, called Trump’s win “a deadly threat to the democratic values of liberty and equality, the rule of law, and reproductive health, rights, and justice in the United States and around the globe.” “The Democrats thought there were enough people who hated Trump or were willing to fear him to win the race,” Jennings said. 2024 election results: Trump wins second term in historic comeback'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat models in LangChain have a number of default methods. For the most part, we'll be using:\n",
        "- **`stream`**: stream back chunks of the response. (chunks main kaam krta ha)\n",
        "- **`invoke`**: call the chain on an input. (direct complete chain ko call krta ha)\n"
      ],
      "metadata": {
        "id": "2qvd3350e3Eq"
      }
    }
  ]
}